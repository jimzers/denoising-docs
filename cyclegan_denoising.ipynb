{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision as tv\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA stuff\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use cycleGAN\n",
    "\n",
    "## what to use?\n",
    "\n",
    "for generator, use encoder/transformer/decoder combo\n",
    "\n",
    "for discriminator, use patchGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# making generator\n",
    "\n",
    "we gotta make residual blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def activation_func(activation):\n",
    "#     return  nn.ModuleDict([\n",
    "#         ['relu', nn.ReLU(inplace=True)],\n",
    "#         ['leaky_relu', nn.LeakyReLU(negative_slope=0.01, inplace=True)],\n",
    "#         ['selu', nn.SELU(inplace=True)],\n",
    "#         ['none', nn.Identity()]\n",
    "#     ])[activation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, activation_fn):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.in_channels, self.out_channels, self.activation = in_channels, out_channels, activation\n",
    "        self.blocks = nn.Identity()\n",
    "        self.activation_fn = activation_fn\n",
    "        self.shortcut = nn.Identity()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        if self.apply_shortcut:\n",
    "            residual = self.shortcut(x)\n",
    "        x += residual\n",
    "        x = self.activate(x)\n",
    "        return x\n",
    "    \n",
    "    @property\n",
    "    def apply_shortcut(self):\n",
    "        return self.in_channels != self.out_channels\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetResidualBlock(ResidualBlock):\n",
    "    def __init__(self, in_channels, out_channels, activation_fn):\n",
    "        super(ResNetResidualBlock, self).__init__(in_channels, \n",
    "                                                       out_channels, \n",
    "                                                       *args,\n",
    "                                                       **kwargs)\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        # input and output dim will be the same for our uses\n",
    "        self.conv1 = nn.Conv2d(input_dim, input_dim, kernel_size=3, padding=1, bias=True)\n",
    "        self.norm1 = nn.InstanceNorm2d(input_dim)\n",
    "        self.relu1 = nn.LeakyReLU(negative_slope=0.01, inplace=True)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(input_dim, input_dim, kernel_size=3, padding=1, bias=True)\n",
    "        self.norm2 = nn.InstanceNorm2d(input_dim)\n",
    "        \n",
    "#         self.relu_final = nn.LeakyReLU(negative_slope=0.01, inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_new = self.conv1(x)\n",
    "        x_new = self.norm1(x_new)\n",
    "        x_new = self.relu1(x_new)\n",
    "        x_new = self.conv2(x_new)\n",
    "        x_new = self.norm2(x_new)\n",
    "        out = x + x_new\n",
    "#         out = self.relu_final(x_new)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CycleGenerator, self).__init__()\n",
    "#         self.activations = nn.ModuleDict({\n",
    "#         'relu', nn.ReLU(inplace=True),\n",
    "#         'leaky_relu', nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "#         'selu', nn.SELU(inplace=True),\n",
    "#         'none', nn.Identity()})\n",
    "        \n",
    "        # do we need this many filter channels \n",
    "        # if we're doing a 1 channel image rather than 3 channel?\n",
    "        \n",
    "#         #encoder section\n",
    "#         self.conv1 = nn.Conv2d(in_channels=1, out_channels=64,\n",
    "#                                kernel_size=(7, 7), padding=0)\n",
    "#         self.conv2 = nn.Conv2d(64, 128, (3, 3), padding=(1, 1), stride=2)\n",
    "#         self.conv3 = nn.Conv2d(128, 256, (3, 3), padding=(1, 1), stride=2)\n",
    "        \n",
    "#         # in the transformer\n",
    "#         self.conv4 = nn.Conv2d(1, 128, (3, 3), padding=(1, 1), stride=2)\n",
    "#         https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/models/networks.py\n",
    "        model = [nn.ReflectionPad2d(3),\n",
    "                 nn.Conv2d(in_channels=1, out_channels=64,\n",
    "                           kernel_size=7, padding=0,\n",
    "                           bias=True),\n",
    "                 nn.InstanceNorm2d(64),\n",
    "                 nn.LeakyReLU(negative_slope=0.01, inplace=True)]\n",
    "    \n",
    "        #downsampling layers\n",
    "        n_downsampling = 2\n",
    "        for i in range(n_downsampling):\n",
    "            mult = 2 ** i\n",
    "            model += [nn.Conv2d(in_channels=64*mult, out_channels=64*mult*2,\n",
    "                           kernel_size=3, stride=2, padding=1,\n",
    "                           bias=True),\n",
    "                      nn.InstanceNorm2d(64*mult*2),\n",
    "                      nn.LeakyReLU(negative_slope=0.01, inplace=True)]\n",
    "            \n",
    "        # resnet blocks layer\n",
    "        num_resnet_blocks = 6\n",
    "        for i in range(num_resnet_blocks):\n",
    "            model += [ResNetBlock(64*mult*2)]\n",
    "            \n",
    "        # upsampling layers\n",
    "        for i in range(n_downsampling):\n",
    "            mult = 2 ** (n_downsampling - i)\n",
    "            model += [nn.ConvTranspose2d(in_channels=64*mult, out_channels=int(64*mult/2),\n",
    "                           kernel_size=3, stride=2, padding=1,\n",
    "                           bias=True),\n",
    "                      nn.InstanceNorm2d(int(64*mult/2)),\n",
    "                      nn.LeakyReLU(negative_slope=0.01, inplace=True)]\n",
    "            \n",
    "        self.model = nn.Sequential(*model)\n",
    "        \n",
    "            \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return model(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CycleDiscriminator, self).__init__()\n",
    "        #https://github.com/aitorzip/PyTorch-CycleGAN/blob/master/models.py\n",
    "        \n",
    "        model = [nn.Conv2d(1, 64, kernel_size=4, stride=2, padding=1), nn.LeakyReLU(0.2, True)]\n",
    "        n_layers = 3\n",
    "        \n",
    "        nf_mult = 1\n",
    "        nf_mult_prev = 1\n",
    "        for n in range(1, n_layers):\n",
    "            nf_mult_prev = nf_mult\n",
    "            nf_mult = min(2 ** n, 8) # 2^n\n",
    "            model += [\n",
    "                nn.Conv2d(64 * nf_mult_prev, 64 * nf_mult, stride=2, padding=1, bias=True),\n",
    "                nn.InstanceNorm2d(64*nf_mult),\n",
    "                nn.LeakyReLU(0.2, True)\n",
    "            ]\n",
    "        nf_mult_prev = nf_mult\n",
    "        nf_mult = min(2 ** n, 8) # 2^n\n",
    "        model += [\n",
    "            nn.Conv2d(64 * nf_mult_prev, 64 * nf_mult, stride=1, padding=1, bias=True),\n",
    "            nn.InstanceNorm2d(64*nf_mult),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    "        \n",
    "        model += [nn.Conv2d(64*nf_mult, 1, kernel_size=4, stride=1, padding=1)] # 1 channel prediction map\n",
    "        self.model = nn.Sequential(*model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageBuffer():\n",
    "    def __init__(self, max_size=50):\n",
    "        assert max_size > 0\n",
    "        self.max_size = max_size\n",
    "        self.data = []\n",
    "    \n",
    "    def push_and_pop(self, data):\n",
    "        to_return = []\n",
    "        for element in data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 4):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN(nn.Module):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        init the cycle gan. add the loss functions\n",
    "        add the models.\n",
    "        add img buffer\n",
    "        '''\n",
    "        \n",
    "        #start with models\n",
    "        generator_clean = CycleGenerator() # dirty to clean\n",
    "        discriminator_clean = CycleDiscriminator() # clean is fake/real\n",
    "        \n",
    "        generator_dirty = CycleGenerator() # clean to dirty\n",
    "        discriminator_clean = CycleDiscriminator() # dirty is fake/real\n",
    "        \n",
    "        # turn on cuda\n",
    "        if use_cuda:\n",
    "            generator_clean.cuda()\n",
    "            discriminator_clean.cuda()\n",
    "            \n",
    "            generator_dirty.cuda()\n",
    "            discriminator_dirty.cuda()\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
